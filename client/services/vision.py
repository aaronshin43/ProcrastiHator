# client/services/vision.py
import sys
import os
from PyQt6.QtCore import QThread, pyqtSignal
import cv2
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from mediapipe import Image as MPImage
from mediapipe.tasks.python.vision.core.image import ImageFormat
import numpy as np
import time

# shared í´ë” importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from shared.protocol import Packet, PacketMeta
from shared.constants import VisionEvents, PacketCategory

class VisionWorker(QThread):
    # ë©”ì¸ UIë¡œ ë³´ë‚¼ ì‹ í˜¸ ì •ì˜
    alert_signal = pyqtSignal(object) # Packet ê°ì²´ë¥¼ ë³´ëƒ„

    def __init__(self, show_debug_window=False):
        super().__init__()
        self.running = False
        self.show_debug_window = show_debug_window  # ë””ë²„ê·¸ ì°½ í‘œì‹œ ì—¬ë¶€
        # MediaPipe Face Landmarker ì´ˆê¸°í™” (0.10.x API)
        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        model_path = os.path.join(os.path.dirname(__file__), 'face_landmarker.task')
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(
                f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}\n"
                f"ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”: python download_mediapipe_model.py"
            )
        
        base_options = python.BaseOptions(model_asset_path=model_path)
        
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            output_face_blendshapes=False,
            output_facial_transformation_matrixes=False,
            num_faces=1,
            min_face_detection_confidence=0.3,  # ë¶€ë¶„ ì–¼êµ´ë„ ê°ì§€í•˜ë„ë¡ ë‚®ì¶¤
            min_face_presence_confidence=0.3,   # ë¶€ë¶„ ì–¼êµ´ë„ ê°ì§€í•˜ë„ë¡ ë‚®ì¶¤
            min_tracking_confidence=0.3,        # tracking ìœ ì§€
            running_mode=vision.RunningMode.IMAGE  # ì´ë¯¸ì§€ ëª¨ë“œ
        )
        
        try:
            self.face_landmarker = vision.FaceLandmarker.create_from_options(options)
        except Exception as e:
            print(f"âš ï¸ FaceLandmarker ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ë‹¤ë¥¸ ë°©ë²•ì„ ì‹œë„í•´ì£¼ì„¸ìš”.")
            raise
        
        # ìƒíƒœ ì¶”ì  (ì¹´ìš´í„° ë°©ì‹)
        self.eye_closed_counter = 0  # ëˆˆ ê°ìŒ ì—°ì† í”„ë ˆì„ ì¹´ìš´í„°
        self.no_face_counter = 0  # ì–¼êµ´ ë¶€ì¬ ì—°ì† í”„ë ˆì„ ì¹´ìš´í„°
        self.gaze_away_counter = 0  # ì‹œì„  ë²—ì–´ë‚¨ ì—°ì† í”„ë ˆì„ ì¹´ìš´í„° (ì–¼êµ´ ìˆìŒ + ëˆˆ ì—†ìŒ)
        self.last_alert_time = {}  # ê° ì´ë²¤íŠ¸ë³„ ë§ˆì§€ë§‰ ì•Œë¦¼ ì‹œê°„ (ì¤‘ë³µ ë°©ì§€)
        
        # Tracking fallback (ì–¼êµ´ì´ ì ê¹ ì•ˆ ë³´ì—¬ë„ ìœ ì§€)
        self.last_face_landmarks = None  # ì´ì „ í”„ë ˆì„ì˜ ì–¼êµ´ ëœë“œë§ˆí¬
        self.last_face_detection_time = 0  # ë§ˆì§€ë§‰ ì–¼êµ´ ê°ì§€ ì‹œê°„
        self.face_tracking_timeout = 0.5  # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•„ë„ 0.5ì´ˆê°„ tracking ìœ ì§€
        
        # EAR ì„ê³„ê°’
        self.EAR_THRESHOLD = 0.25  # ëˆˆ ê°ìŒ ì„ê³„ê°’
        self.EAR_CONSECUTIVE_FRAMES = 100  # ì—°ì† í”„ë ˆì„ ìˆ˜ (ì¡¸ìŒ ê°ì§€ ì„ê³„ê°’)
        self.NO_FACE_CONSECUTIVE_FRAMES = 100  # ì–¼êµ´ ë¶€ì¬ ì—°ì† í”„ë ˆì„ ìˆ˜
        
        # GAZE_AWAY: ì–¼êµ´ ìˆìŒ + ëˆˆ ì—†ìŒì´ ì§€ì†ë˜ëŠ” í”„ë ˆì„ ìˆ˜
        self.GAZE_AWAY_CONSECUTIVE_FRAMES = 10  # ì—°ì† í”„ë ˆì„ ìˆ˜ (ì•½ 5ì´ˆ)
        
        # ì–¼êµ´ ì™¸ê³½ì„  ëœë“œë§ˆí¬ (ê·¸ë¦¬ê¸°ìš©)
        self.FACE_OVAL = [10, 338, 297, 332, 284, 251, 389, 356, 454, 323, 361, 288, 397, 365, 379, 378, 400, 377, 152, 148, 176, 149, 150, 136, 172, 58, 132, 93, 234, 127, 162, 21, 54, 103, 67, 109]
        
        # ì–¼êµ´ ë°©í–¥ ê³„ì‚°ìš© ì¶”ê°€ ëœë“œë§ˆí¬
        self.LEFT_EYE_INNER = 133
        self.LEFT_EYE_OUTER = 33
        self.RIGHT_EYE_INNER = 362
        self.RIGHT_EYE_OUTER = 263
        self.FOREHEAD = 10
        
        # ëˆˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (EAR ê³„ì‚°ìš©)
        self.LEFT_EYE_EAR = [33, 160, 158, 133, 153, 144]
        self.RIGHT_EYE_EAR = [362, 385, 387, 263, 390, 374]
        
        # ì–¼êµ´ ë°©í–¥ ê³„ì‚°ìš© ëœë“œë§ˆí¬
        self.NOSE_TIP = 1
        self.CHIN = 175
        self.LEFT_EYE_CENTER = 33
        self.RIGHT_EYE_CENTER = 362
    
    def calculate_ear(self, landmarks, eye_indices):
        """Eye Aspect Ratio (EAR) ê³„ì‚°"""
        # MediaPipe 0.10.xëŠ” landmarksê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ
        # ìˆ˜ì§ ê±°ë¦¬ ê³„ì‚°
        vertical_1 = np.linalg.norm(
            np.array([landmarks[eye_indices[1]].x, landmarks[eye_indices[1]].y]) -
            np.array([landmarks[eye_indices[5]].x, landmarks[eye_indices[5]].y])
        )
        vertical_2 = np.linalg.norm(
            np.array([landmarks[eye_indices[2]].x, landmarks[eye_indices[2]].y]) -
            np.array([landmarks[eye_indices[4]].x, landmarks[eye_indices[4]].y])
        )
        
        # ìˆ˜í‰ ê±°ë¦¬ ê³„ì‚°
        horizontal = np.linalg.norm(
            np.array([landmarks[eye_indices[0]].x, landmarks[eye_indices[0]].y]) -
            np.array([landmarks[eye_indices[3]].x, landmarks[eye_indices[3]].y])
        )
        
        # EAR ê³„ì‚°
        if horizontal == 0:
            return 0.0
        ear = (vertical_1 + vertical_2) / (2.0 * horizontal)
        return ear
    
    def should_alert(self, event_type, cooldown_seconds=5):
        """ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (ì¿¨ë‹¤ìš´)"""
        current_time = time.time()
        last_time = self.last_alert_time.get(event_type, 0)
        
        if current_time - last_time < cooldown_seconds:
            return False
        
        self.last_alert_time[event_type] = current_time
        return True
    
    def has_eyes_visible(self, face_landmarks):
        """ëˆˆ ëœë“œë§ˆí¬ê°€ ë³´ì´ëŠ”ì§€ í™•ì¸ (ì–¼êµ´ì´ ì˜†ìœ¼ë¡œ ëŒì•„ê°€ë©´ ëˆˆì´ ê°€ë ¤ì§ˆ ìˆ˜ ìˆìŒ)"""
        try:
            # ì™¼ìª½ ëˆˆê³¼ ì˜¤ë¥¸ìª½ ëˆˆì˜ ì£¼ìš” ëœë“œë§ˆí¬ í™•ì¸
            left_eye_valid = all(i < len(face_landmarks) for i in self.LEFT_EYE_EAR)
            right_eye_valid = all(i < len(face_landmarks) for i in self.RIGHT_EYE_EAR)
            
            # ì–‘ìª½ ëˆˆ ì¤‘ í•˜ë‚˜ë¼ë„ ëœë“œë§ˆí¬ê°€ ìœ íš¨í•˜ë©´ ëˆˆì´ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨
            return left_eye_valid or right_eye_valid
        except (IndexError, AttributeError):
            return False
    
    def calculate_face_orientation(self, landmarks, frame_width, frame_height):
        """ì–¼êµ´ ë°©í–¥ ê³„ì‚° (pitch, yaw) - ê¸°í•˜í•™ì  ê³„ì‚° ê¸°ë°˜"""
        # ì£¼ìš” ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ
        nose_tip = landmarks[self.NOSE_TIP]
        chin = landmarks[self.CHIN]
        left_eye_inner = landmarks[self.LEFT_EYE_INNER]
        left_eye_outer = landmarks[self.LEFT_EYE_OUTER]
        right_eye_inner = landmarks[self.RIGHT_EYE_INNER]
        right_eye_outer = landmarks[self.RIGHT_EYE_OUTER]
        forehead = landmarks[self.FOREHEAD]
        
        # 2D ì¢Œí‘œ ì¶”ì¶œ (x, yë§Œ ì‚¬ìš© - ë” ì•ˆì •ì )
        def get_2d(landmark):
            return np.array([landmark.x, landmark.y])
        
        nose_2d = get_2d(nose_tip)
        chin_2d = get_2d(chin)
        left_eye_inner_2d = get_2d(left_eye_inner)
        left_eye_outer_2d = get_2d(left_eye_outer)
        right_eye_inner_2d = get_2d(right_eye_inner)
        right_eye_outer_2d = get_2d(right_eye_outer)
        forehead_2d = get_2d(forehead)
        
        # ë‘ ëˆˆì˜ ì¤‘ì‹¬ì  ê³„ì‚°
        left_eye_center_2d = (left_eye_inner_2d + left_eye_outer_2d) / 2
        right_eye_center_2d = (right_eye_inner_2d + right_eye_outer_2d) / 2
        eye_center_2d = (left_eye_center_2d + right_eye_center_2d) / 2
        
        # ë‘ ëˆˆ ì‚¬ì´ì˜ ê±°ë¦¬ (ì •ê·œí™”ëœ ì¢Œí‘œ ê¸°ì¤€)
        eye_distance = np.linalg.norm(right_eye_center_2d - left_eye_center_2d)
        
        # ì–¼êµ´ ë†’ì´ (ì´ë§ˆì—ì„œ í„±ê¹Œì§€)
        face_height = np.linalg.norm(chin_2d - forehead_2d)
        
        # Yaw ê³„ì‚° (ì¢Œìš° íšŒì „) - ì½”ê°€ ë‘ ëˆˆ ì¤‘ì‹¬ì„ ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ì§€
        # ì •ë©´ì„ ë³´ë©´ ì½”ëŠ” ë‘ ëˆˆ ì¤‘ì‹¬ì„ ì˜ ì¤‘ì•™ì— ìˆì–´ì•¼ í•¨
        eye_midpoint_x = eye_center_2d[0]
        nose_x = nose_2d[0]
        
        # ì½”ê°€ ëˆˆ ì¤‘ì‹¬ì„ ì—ì„œ ë²—ì–´ë‚œ ê±°ë¦¬ (ì •ê·œí™”)
        if eye_distance > 0:
            yaw_offset = (nose_x - eye_midpoint_x) / eye_distance
            # ê°ë„ë¡œ ë³€í™˜ (ëŒ€ëµì ì¸ ë³€í™˜: ì •ë©´ ê¸°ì¤€ Â±30ë„ ë²”ìœ„)
            # yaw_offsetì´ 0ì´ë©´ ì •ë©´, Â±0.5ë©´ ì•½ 30ë„ íšŒì „
            yaw_degrees = yaw_offset * 60.0  # ìŠ¤ì¼€ì¼ ì¡°ì •
        else:
            yaw_degrees = 0.0
        
        # Pitch ê³„ì‚° (ìƒí•˜ íšŒì „) - ì½”ê°€ ëˆˆ ì¤‘ì‹¬ì„ ì—ì„œ ì–¼ë§ˆë‚˜ ìœ„ì•„ë˜ë¡œ ë²—ì–´ë‚¬ëŠ”ì§€
        # ì •ë©´ì„ ë³´ë©´ ì½”ëŠ” ëˆˆ ì¤‘ì‹¬ì„ ë³´ë‹¤ ì•½ê°„ ì•„ë˜ì— ìˆì–´ì•¼ í•¨
        eye_midpoint_y = eye_center_2d[1]
        nose_y = nose_2d[1]
        
        # ì½”ê°€ ëˆˆ ì¤‘ì‹¬ì„ ë³´ë‹¤ ì•„ë˜ì— ìˆìœ¼ë©´ ì–‘ìˆ˜ (ì•„ë˜ë¡œ ê³ ê°œë¥¼ ìˆ™ì„)
        # ì½”ê°€ ëˆˆ ì¤‘ì‹¬ì„ ë³´ë‹¤ ìœ„ì— ìˆìœ¼ë©´ ìŒìˆ˜ (ìœ„ë¡œ ê³ ê°œë¥¼ ë“¦)
        if face_height > 0:
            # ì •ë©´ ê¸°ì¤€ìœ¼ë¡œ ì½”ëŠ” ëˆˆë³´ë‹¤ ì•½ê°„ ì•„ë˜ì— ìˆì–´ì•¼ í•¨
            # ì •ìƒì ì¸ ìœ„ì¹˜ ì°¨ì´ë¥¼ ë³´ì •
            normal_nose_offset = 0.05  # ì •ë©´ ê¸°ì¤€ ì½”ì˜ ì •ìƒ ìœ„ì¹˜ (ëˆˆë³´ë‹¤ ì•½ê°„ ì•„ë˜)
            pitch_offset = (nose_y - eye_midpoint_y - normal_nose_offset) / face_height
            # ê°ë„ë¡œ ë³€í™˜
            pitch_degrees = pitch_offset * 60.0  # ìŠ¤ì¼€ì¼ ì¡°ì •
        else:
            pitch_degrees = 0.0
        
        return pitch_degrees, yaw_degrees
    
    def draw_debug_info(self, frame, face_landmarks, avg_ear, pitch, yaw, is_sleeping, is_absent, is_gaze_away):
        """ë””ë²„ê·¸ ì •ë³´ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°"""
        frame_height, frame_width = frame.shape[:2]
        
        # ìƒíƒœ ì •ë³´ í…ìŠ¤íŠ¸
        y_offset = 30
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        thickness = 2
        
        # ì–¼êµ´ ê°ì§€ ì—¬ë¶€ í‘œì‹œ
        if face_landmarks:
            # ì–¼êµ´ì´ ê°ì§€ë¨
            cv2.putText(frame, "Face: DETECTED", (10, y_offset),
                       font, font_scale, (0, 255, 0), thickness)
            
            # ì–¼êµ´ ì™¸ê³½ì„  ê·¸ë¦¬ê¸° (ì–¼êµ´ ê°ì§€ í‘œì‹œ)
            face_oval_points = []
            for idx in self.FACE_OVAL:
                if idx < len(face_landmarks):
                    point = face_landmarks[idx]
                    x = int(point.x * frame_width)
                    y = int(point.y * frame_height)
                    face_oval_points.append((x, y))
            
            if len(face_oval_points) > 2:
                pts = np.array(face_oval_points, np.int32)
                cv2.polylines(frame, [pts], True, (255, 0, 255), 2)  # ë§ˆì  íƒ€ìƒ‰ìœ¼ë¡œ ì–¼êµ´ ì™¸ê³½ì„ 
            
            # ëˆˆ ê°€ì‹œì„± í™•ì¸
            eyes_visible = self.has_eyes_visible(face_landmarks)
            
            # ëˆˆ ì˜ì—­ ê·¸ë¦¬ê¸° (ëˆˆì´ ë³´ì¼ ë•Œë§Œ)
            if eyes_visible:
                for eye_indices in [self.LEFT_EYE_EAR, self.RIGHT_EYE_EAR]:
                    eye_points = []
                    for idx in eye_indices:
                        if idx < len(face_landmarks):
                            point = face_landmarks[idx]
                            x = int(point.x * frame_width)
                            y = int(point.y * frame_height)
                            eye_points.append((x, y))
                            cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)
                    
                    # ëˆˆ ìœ¤ê³½ì„  ê·¸ë¦¬ê¸°
                    if len(eye_points) >= 4:
                        pts = np.array(eye_points, np.int32)
                        cv2.polylines(frame, [pts], True, (0, 255, 0), 1)
            else:
                # ëˆˆì´ ì•ˆ ë³´ì´ëŠ” ê²½ìš° í‘œì‹œ
                cv2.putText(frame, "Eyes: NOT VISIBLE", (10, y_offset + 25),
                           font, font_scale, (0, 165, 255), thickness)
            
            y_offset += 25
            
            # ëˆˆ ê°€ì‹œì„± í‘œì‹œ
            eyes_status = "VISIBLE" if eyes_visible else "NOT VISIBLE"
            eyes_color = (0, 255, 0) if eyes_visible else (0, 165, 255)
            cv2.putText(frame, f"Eyes: {eyes_status}", (10, y_offset),
                       font, font_scale, eyes_color, thickness)
            y_offset += 25
            
            # EAR ê°’ (ëˆˆì´ ë³´ì¼ ë•Œë§Œ í‘œì‹œ)
            if eyes_visible and avg_ear > 0:
                ear_color = (0, 255, 0) if avg_ear >= self.EAR_THRESHOLD else (0, 0, 255)
                cv2.putText(frame, f"EAR: {avg_ear:.3f}", (10, y_offset), 
                           font, font_scale, ear_color, thickness)
                y_offset += 25
            
            # ì‹œì„  ë²—ì–´ë‚¨ í”„ë ˆì„ ìˆ˜
            gaze_away_color = (255, 255, 255) if not is_gaze_away else (0, 165, 255)
            cv2.putText(frame, f"Gaze Away Frames: {self.gaze_away_counter}/{self.GAZE_AWAY_CONSECUTIVE_FRAMES}", 
                       (10, y_offset), font, font_scale, gaze_away_color, thickness)
            y_offset += 25
            
            # ëˆˆ ê°ìŒ í”„ë ˆì„ ìˆ˜
            cv2.putText(frame, f"Closed Frames: {self.eye_closed_counter}/{self.EAR_CONSECUTIVE_FRAMES}", 
                       (10, y_offset), font, font_scale, (255, 255, 255), thickness)
            y_offset += 25
        else:
            # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ
            cv2.putText(frame, "Face: NOT DETECTED", (10, y_offset),
                       font, font_scale, (0, 0, 255), thickness)
            y_offset += 25
            
            # ì–¼êµ´ ë¶€ì¬ í”„ë ˆì„ ìˆ˜
            cv2.putText(frame, f"No Face Frames: {self.no_face_counter}/{self.NO_FACE_CONSECUTIVE_FRAMES}", 
                       (10, y_offset), font, font_scale, (255, 255, 255), thickness)
            y_offset += 25
        
        # ìƒíƒœ í‘œì‹œ (í•­ìƒ í‘œì‹œ)
        if is_sleeping:
            cv2.putText(frame, "SLEEPING!", (10, y_offset),
                       font, 0.8, (0, 0, 255), 2)
            y_offset += 30
        if is_absent:
            cv2.putText(frame, "ABSENT!", (10, y_offset),
                       font, 0.8, (255, 0, 0), 2)
            y_offset += 30
        if is_gaze_away:
            cv2.putText(frame, "GAZE AWAY!", (10, y_offset),
                       font, 0.8, (0, 165, 255), 2)
            y_offset += 30
        
        return frame

    def run(self):
        self.running = True
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("[ERROR] ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ìº ì´ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            self.running = False
            return
        
        print("[OK] ì›¹ìº  ì—°ê²° ì„±ê³µ - Vision Worker ì‹œì‘")
        
        try:
            while self.running:
                try:
                    ret, frame = cap.read()
                    if not ret:
                        print("[WARNING] í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        continue
                    
                    # MediaPipe Face Landmarker ì²˜ë¦¬
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    mp_image = MPImage(image_format=ImageFormat.SRGB, data=frame_rgb)
                    detection_result = self.face_landmarker.detect(mp_image)
                    
                    is_sleeping = False
                    is_absent = False
                    is_gaze_away = False
                    avg_ear = 0.0  # ê¸°ë³¸ê°’
                    pitch, yaw = 0.0, 0.0  # ì–¼êµ´ ë°©í–¥ (ê°ë„, ë„ ë‹¨ìœ„)
                    
                    current_time = time.time()
                    face_detected = False
                    face_landmarks = None
                    
                    # 1ë‹¨ê³„: ì–¼êµ´ ê°ì§€ í™•ì¸
                    if detection_result.face_landmarks and len(detection_result.face_landmarks) > 0:
                        face_landmarks = detection_result.face_landmarks[0]
                        self.last_face_landmarks = face_landmarks
                        self.last_face_detection_time = current_time
                        face_detected = True
                        self.no_face_counter = 0  # ì–¼êµ´ ê°ì§€ë˜ë©´ ì¹´ìš´í„° ë¦¬ì…‹
                    
                    # 2ë‹¨ê³„: Tracking fallback (ì§§ì€ ì‹œê°„ë§Œ)
                    elif self.last_face_landmarks is not None:
                        time_since_last = current_time - self.last_face_detection_time
                        if time_since_last < self.face_tracking_timeout:
                            face_landmarks = self.last_face_landmarks
                            face_detected = True
                        else:
                            # Tracking timeout - ì–¼êµ´ì´ ì™„ì „íˆ ì‚¬ë¼ì§„ ê²ƒìœ¼ë¡œ ê°„ì£¼
                            self.last_face_landmarks = None
                            self.no_face_counter += 1
                            self.eye_closed_counter = 0
                            self.gaze_away_counter = 0
                    else:
                        # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šê³  ì´ì „ ì •ë³´ë„ ì—†ìŒ
                        self.no_face_counter += 1
                        self.eye_closed_counter = 0
                        self.gaze_away_counter = 0
                    
                    # 3ë‹¨ê³„: ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆê±°ë‚˜ tracking ì¤‘ì¸ ê²½ìš°
                    if face_detected and face_landmarks is not None:
                        # ëˆˆ ê°€ì‹œì„± í™•ì¸
                        eyes_visible = self.has_eyes_visible(face_landmarks)
                        
                        if eyes_visible:
                            # ì–¼êµ´ + ëˆˆì´ ë³´ì„ - ì •ìƒ ìƒíƒœ
                            self.gaze_away_counter = 0  # GAZE_AWAY ì¹´ìš´í„° ë¦¬ì…‹
                            
                            # ëˆˆ ê°ìŒ ê°ì§€ (EAR ê³„ì‚°)
                            try:
                                left_ear = self.calculate_ear(face_landmarks, self.LEFT_EYE_EAR)
                            except (IndexError, AttributeError):
                                left_ear = 0.0
                            
                            try:
                                right_ear = self.calculate_ear(face_landmarks, self.RIGHT_EYE_EAR)
                            except (IndexError, AttributeError):
                                right_ear = 0.0
                            
                            if left_ear > 0 and right_ear > 0:
                                avg_ear = (left_ear + right_ear) / 2.0
                            elif left_ear > 0:
                                avg_ear = left_ear
                            elif right_ear > 0:
                                avg_ear = right_ear
                            
                            # ëˆˆì´ ê°ê²¼ëŠ”ì§€ í™•ì¸
                            if avg_ear > 0:
                                if avg_ear < self.EAR_THRESHOLD:
                                    # ëˆˆì´ ê°ìŒ - ì¹´ìš´í„° ì¦ê°€
                                    self.eye_closed_counter += 1
                                else:
                                    # ëˆˆì´ ì—´ë¦¼ - ì¹´ìš´í„° ë¦¬ì…‹
                                    self.eye_closed_counter = 0
                                
                                # ì—°ì†ìœ¼ë¡œ ëˆˆì„ ê°ê³  ìˆìœ¼ë©´ ì¡¸ìŒ ê°ì§€
                                if self.eye_closed_counter >= self.EAR_CONSECUTIVE_FRAMES:
                                    is_sleeping = True
                        else:
                            # ì–¼êµ´ì€ ë³´ì´ì§€ë§Œ ëˆˆì´ ì•ˆ ë³´ì„ - GAZE_AWAY ìƒíƒœ
                            self.eye_closed_counter = 0  # ëˆˆ ê°ìŒ ì¹´ìš´í„°ëŠ” ë¦¬ì…‹
                            self.gaze_away_counter += 1  # GAZE_AWAY ì¹´ìš´í„° ì¦ê°€
                            
                            # ì—°ì†ìœ¼ë¡œ ì–¼êµ´ì€ ë³´ì´ì§€ë§Œ ëˆˆì´ ì•ˆ ë³´ì´ë©´ GAZE_AWAY ê°ì§€
                            if self.gaze_away_counter >= self.GAZE_AWAY_CONSECUTIVE_FRAMES:
                                is_gaze_away = True
                    
                    # 4ë‹¨ê³„: ì–¼êµ´ì´ ì™„ì „íˆ ì‚¬ë¼ì§„ ê²½ìš°
                    if not face_detected and self.last_face_landmarks is None:
                        if self.no_face_counter >= self.NO_FACE_CONSECUTIVE_FRAMES:
                            is_absent = True
                    
                    # ì¡¸ìŒ ê°ì§€ ì‹œ Packet ë°œì†¡
                    if is_sleeping:
                        if self.should_alert(VisionEvents.SLEEPING):
                            packet = Packet(
                                event=VisionEvents.SLEEPING,
                                data={"confidence": 0.9, "ear": avg_ear},
                                meta=PacketMeta(category=PacketCategory.VISION)
                            )
                            self.alert_signal.emit(packet)
                    
                    # ì–¼êµ´ ë¶€ì¬ ê°ì§€ ì‹œ Packet ë°œì†¡
                    if is_absent:
                        if self.should_alert(VisionEvents.ABSENT):
                            packet = Packet(
                                event=VisionEvents.ABSENT,
                                data={"confidence": 0.9, "duration": self.no_face_counter},
                                meta=PacketMeta(category=PacketCategory.VISION)
                            )
                            self.alert_signal.emit(packet)
                    
                    # ì‹œì„  ë²—ì–´ë‚¨ ê°ì§€ ì‹œ Packet ë°œì†¡ (ì–¼êµ´ ìˆìŒ + ëˆˆ ì—†ìŒ)
                    if is_gaze_away:
                        if self.should_alert(VisionEvents.GAZE_AWAY):
                            packet = Packet(
                                event=VisionEvents.GAZE_AWAY,
                                data={
                                    "confidence": 0.9, 
                                    "reason": "eyes_not_visible",
                                    "duration": self.gaze_away_counter
                                },
                                meta=PacketMeta(category=PacketCategory.VISION)
                            )
                            self.alert_signal.emit(packet)
                    
                    # ë””ë²„ê·¸ ì°½ í‘œì‹œ (ì–¼êµ´ì´ ìˆë“  ì—†ë“  í•­ìƒ í‘œì‹œ)
                    if self.show_debug_window:
                        # ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ
                        face_landmarks_for_draw = None
                        if detection_result.face_landmarks:
                            face_landmarks_for_draw = detection_result.face_landmarks[0]
                        
                        debug_frame = self.draw_debug_info(
                            frame.copy(), 
                            face_landmarks_for_draw,
                            avg_ear, pitch, yaw, is_sleeping, is_absent, is_gaze_away
                        )
                        cv2.imshow('Vision Debug', debug_frame)
                        # 'q' í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œ
                        if cv2.waitKey(1) & 0xFF == ord('q'):
                            self.running = False
                    
                    # time.sleep(0.05) # 0.1ì´ˆ ëŒ€ê¸° (10 FPS)
                
                except Exception as e:
                    # í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ ì¶œë ¥í•˜ê³  ê³„ì† ì§„í–‰
                    print(f"[ERROR] í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    import traceback
                    traceback.print_exc()
                    # ì˜ˆì™¸ ë°œìƒí•´ë„ ë£¨í”„ëŠ” ê³„ì† ì§„í–‰ (ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬)
                    continue
        
        except Exception as e:
            # ì „ì²´ ë£¨í”„ì—ì„œ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ ì‹œ
            print(f"[ERROR] Vision Worker ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # ì •ë¦¬ ì‘ì—…ì€ í•­ìƒ ì‹¤í–‰
            self.running = False
            cap.release()
            if self.show_debug_window:
                cv2.destroyAllWindows()
            print("[OK] Vision Worker ì¢…ë£Œ")
    
    def stop(self):
        """ìŠ¤ë ˆë“œ ì¢…ë£Œ"""
        self.running = False