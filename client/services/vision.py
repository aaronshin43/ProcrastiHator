# client/services/vision.py
import sys
import os
from PyQt6.QtCore import QThread, pyqtSignal
import cv2
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from mediapipe import Image as MPImage
from mediapipe.tasks.python.vision.core.image import ImageFormat
import numpy as np
import time

# shared í´ë” importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from shared.protocol import Packet, PacketMeta
from shared.constants import VisionEvents, PacketCategory

class VisionWorker(QThread):
    # ë©”ì¸ UIë¡œ ë³´ë‚¼ ì‹ í˜¸ ì •ì˜
    alert_signal = pyqtSignal(object) # Packet ê°ì²´ë¥¼ ë³´ëƒ„
    debug_frame_signal = pyqtSignal(np.ndarray) # ë””ë²„ê·¸ ì´ë¯¸ì§€(OpenCV í¬ë§·) ë³´ëƒ„

    def __init__(self, show_debug_window=False):
        super().__init__()
        self.running = False
        self.show_debug_window = show_debug_window  # ë””ë²„ê·¸ ì´ë¯¸ì§€ë¥¼ ì†¡ì¶œí• ì§€ ì—¬ë¶€
        # MediaPipe Face Landmarker ì´ˆê¸°í™” (0.10.x API)
        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        model_path = os.path.join(os.path.dirname(__file__), 'face_landmarker.task')
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(
                f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}\n"
                f"ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”: python download_mediapipe_model.py"
            )
        
        base_options = python.BaseOptions(model_asset_path=model_path)
        
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            output_face_blendshapes=False,
            output_facial_transformation_matrixes=False,
            num_faces=1,
            min_face_detection_confidence=0.5,
            min_face_presence_confidence=0.5,
            min_tracking_confidence=0.5,
            running_mode=vision.RunningMode.IMAGE  # ì´ë¯¸ì§€ ëª¨ë“œ
        )
        
        try:
            self.face_landmarker = vision.FaceLandmarker.create_from_options(options)
        except Exception as e:
            print(f"âš ï¸ FaceLandmarker ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ë‹¤ë¥¸ ë°©ë²•ì„ ì‹œë„í•´ì£¼ì„¸ìš”.")
            raise
        
        # ìƒíƒœ ì¶”ì  (ì¹´ìš´í„° ë°©ì‹)
        self.eye_closed_counter = 0  # ëˆˆ ê°ìŒ ì—°ì† í”„ë ˆì„ ì¹´ìš´í„°
        self.no_face_counter = 0  # ì–¼êµ´ ë¶€ì¬ ì—°ì† í”„ë ˆì„ ì¹´ìš´í„°
        self.gaze_away_counter = 0  # ì‹œì„  ë²—ì–´ë‚¨ ì—°ì† í”„ë ˆì„ ì¹´ìš´í„°
        self.last_alert_time = {}  # ê° ì´ë²¤íŠ¸ë³„ ë§ˆì§€ë§‰ ì•Œë¦¼ ì‹œê°„ (ì¤‘ë³µ ë°©ì§€)
        
        # EAR ì„ê³„ê°’
        self.EAR_THRESHOLD = 0.25  # ëˆˆ ê°ìŒ ì„ê³„ê°’
        self.EAR_CONSECUTIVE_FRAMES = 100  # ì—°ì† í”„ë ˆì„ ìˆ˜ (ì¡¸ìŒ ê°ì§€ ì„ê³„ê°’)
        self.NO_FACE_CONSECUTIVE_FRAMES = 100  # ì–¼êµ´ ë¶€ì¬ ì—°ì† í”„ë ˆì„ ìˆ˜
        
        # ì‹œì„  ë²—ì–´ë‚¨ ì„ê³„ê°’ (ê°ë„ ê¸°ì¤€, ë„ ë‹¨ìœ„)
        self.GAZE_PITCH_THRESHOLD = 25.0  # ìœ„/ì•„ë˜ ì‹œì„  ë²—ì–´ë‚¨ ì„ê³„ê°’ (ë„)
        self.GAZE_YAW_THRESHOLD = 30.0  # ì¢Œ/ìš° ì‹œì„  ë²—ì–´ë‚¨ ì„ê³„ê°’ (ë„)
        self.GAZE_AWAY_CONSECUTIVE_FRAMES = 100  # ì—°ì† í”„ë ˆì„ ìˆ˜ (ì‹œì„  ë²—ì–´ë‚¨ ê°ì§€ ì„ê³„ê°’, ì•½ 50ì´ˆ)
        
        # ì–¼êµ´ ë°©í–¥ ê³„ì‚°ìš© ì¶”ê°€ ëœë“œë§ˆí¬
        self.LEFT_EYE_INNER = 133
        self.LEFT_EYE_OUTER = 33
        self.RIGHT_EYE_INNER = 362
        self.RIGHT_EYE_OUTER = 263
        self.FOREHEAD = 10
        
        # ëˆˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (EAR ê³„ì‚°ìš©)
        self.LEFT_EYE_EAR = [33, 160, 158, 133, 153, 144]
        self.RIGHT_EYE_EAR = [362, 385, 387, 263, 390, 374]
        
        # ì–¼êµ´ ë°©í–¥ ê³„ì‚°ìš© ëœë“œë§ˆí¬
        self.NOSE_TIP = 1
        self.CHIN = 175
        self.LEFT_EYE_CENTER = 33
        self.RIGHT_EYE_CENTER = 362
        
        # ë³¼ ëœë“œë§ˆí¬ (GAZE_AWAY ê°ì§€ìš©) - ì•ˆìª½ ë³¼ ì˜ì—­ ì‚¬ìš©
        self.LEFT_CHEEK = 118   # ì™¼ìª½ ë³¼ ì•ˆìª½ (face oval, 116ë³´ë‹¤ ì•ˆìª½)
        self.RIGHT_CHEEK = 347  # ì˜¤ë¥¸ìª½ ë³¼ ì•ˆìª½ (face oval, 345ë³´ë‹¤ ì•ˆìª½)
        
        # ë³¼ ê°€ì‹œì„± ê²€ì‚¬ ì„ê³„ê°’ (ë¯¼ê°ë„ ë‚®ì¶¤)
        self.CHEEK_Z_DEPTH_THRESHOLD = 0.15  # ë³¼ì˜ z-depth ì°¨ì´ ì„ê³„ê°’ (ì–¼êµ´ì´ ì˜†ìœ¼ë¡œ ëŒì•„ê°€ë©´ z ê°’ ì°¨ì´ê°€ ì»¤ì§) - ë” ì™„í™”
        self.CHEEK_POSITION_THRESHOLD = 0.40  # ë³¼ì˜ ìƒëŒ€ì  ìœ„ì¹˜ ì„ê³„ê°’ (ì–¼êµ´ ì¤‘ì‹¬ì—ì„œ ë²—ì–´ë‚œ ì •ë„) - ë” ì™„í™”
        self.CHEEK_NOSE_Z_THRESHOLD = 0.20  # ë³¼ê³¼ ì½”ì˜ z-depth ì°¨ì´ ì„ê³„ê°’ - ë” ì™„í™”
        self.CHEEK_Z_DIFF_PASS_THRESHOLD = 0.03  # z-depth ì°¨ì´ê°€ ì´ ê°’ë³´ë‹¤ ì‘ìœ¼ë©´ ì¦‰ì‹œ í†µê³¼ (ì •ë©´ íŒë‹¨)
    
    def calculate_ear(self, landmarks, eye_indices):
        """Eye Aspect Ratio (EAR) ê³„ì‚°"""
        # MediaPipe 0.10.xëŠ” landmarksê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ
        # ìˆ˜ì§ ê±°ë¦¬ ê³„ì‚°
        vertical_1 = np.linalg.norm(
            np.array([landmarks[eye_indices[1]].x, landmarks[eye_indices[1]].y]) -
            np.array([landmarks[eye_indices[5]].x, landmarks[eye_indices[5]].y])
        )
        vertical_2 = np.linalg.norm(
            np.array([landmarks[eye_indices[2]].x, landmarks[eye_indices[2]].y]) -
            np.array([landmarks[eye_indices[4]].x, landmarks[eye_indices[4]].y])
        )
        
        # ìˆ˜í‰ ê±°ë¦¬ ê³„ì‚°
        horizontal = np.linalg.norm(
            np.array([landmarks[eye_indices[0]].x, landmarks[eye_indices[0]].y]) -
            np.array([landmarks[eye_indices[3]].x, landmarks[eye_indices[3]].y])
        )
        
        # EAR ê³„ì‚°
        if horizontal == 0:
            return 0.0
        ear = (vertical_1 + vertical_2) / (2.0 * horizontal)
        return ear
    
    def should_alert(self, event_type, cooldown_seconds=5):
        """ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (ì¿¨ë‹¤ìš´)"""
        current_time = time.time()
        last_time = self.last_alert_time.get(event_type, 0)
        
        if current_time - last_time < cooldown_seconds:
            return False
        
        self.last_alert_time[event_type] = current_time
        return True
    
    def has_cheeks_visible(self, face_landmarks):
        """ë³¼(left/right cheek)ì´ ì‹¤ì œë¡œ ë³´ì´ëŠ”ì§€ í™•ì¸ (z-depth ë° ìœ„ì¹˜ ê²€ì¦)"""
        try:
            # ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ ë²”ìœ„ í™•ì¸
            if (self.LEFT_CHEEK >= len(face_landmarks) or 
                self.RIGHT_CHEEK >= len(face_landmarks) or
                self.NOSE_TIP >= len(face_landmarks)):
                return False
            
            # ë³¼ê³¼ ì½” ëœë“œë§ˆí¬ ì¶”ì¶œ
            left_cheek = face_landmarks[self.LEFT_CHEEK]
            right_cheek = face_landmarks[self.RIGHT_CHEEK]
            nose_tip = face_landmarks[self.NOSE_TIP]
            
            # z-depth ì¶”ì¶œ (ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ 0)
            def get_z(landmark):
                return getattr(landmark, 'z', 0.0)
            
            left_cheek_z = get_z(left_cheek)
            right_cheek_z = get_z(right_cheek)
            nose_z = get_z(nose_tip)
            
            # ë°©ë²• 1: z-depth ì°¨ì´ í™•ì¸ (ê°€ì¥ ì‹ ë¢°í•  ë§Œí•œ ë°©ë²•)
            # ì–¼êµ´ì´ ì˜†ìœ¼ë¡œ ëŒì•„ê°€ë©´ í•œìª½ ë³¼ì˜ z ê°’ì´ ë‹¤ë¥¸ ìª½ë³´ë‹¤ í¬ê²Œ ì°¨ì´ë‚¨
            z_diff = abs(left_cheek_z - right_cheek_z)
            
            # z-depth ì°¨ì´ê°€ ë§¤ìš° ì‘ìœ¼ë©´ (ì •ë©´ì„ ë³´ê³  ìˆìŒ) ë¬´ì¡°ê±´ í†µê³¼
            if z_diff < self.CHEEK_Z_DIFF_PASS_THRESHOLD:
                return True
            
            # z-depth ì°¨ì´ê°€ í¬ë©´ ì–¼êµ´ì´ ì˜†ìœ¼ë¡œ ëŒì•„ê°„ ê²ƒìœ¼ë¡œ íŒë‹¨
            if z_diff > self.CHEEK_Z_DEPTH_THRESHOLD:
                return False
            
            # ë°©ë²• 2: ë³¼ì˜ ìƒëŒ€ì  ìœ„ì¹˜ í™•ì¸ (ë³´ì¡° ê²€ì¦)
            # ì–¼êµ´ ì¤‘ì‹¬(ì½”)ì—ì„œ ë³¼ê¹Œì§€ì˜ ê±°ë¦¬ í™•ì¸
            nose_x, nose_y = nose_tip.x, nose_tip.y
            left_cheek_x, left_cheek_y = left_cheek.x, left_cheek.y
            right_cheek_x, right_cheek_y = right_cheek.x, right_cheek.y
            
            # ì½”ì—ì„œ ê° ë³¼ê¹Œì§€ì˜ ê±°ë¦¬
            left_distance = np.sqrt((left_cheek_x - nose_x)**2 + (left_cheek_y - nose_y)**2)
            right_distance = np.sqrt((right_cheek_x - nose_x)**2 + (right_cheek_y - nose_y)**2)
            
            # ë‘ ë³¼ ì‚¬ì´ì˜ ê±°ë¦¬
            cheek_distance = np.sqrt((right_cheek_x - left_cheek_x)**2 + (right_cheek_y - left_cheek_y)**2)
            
            # ì–¼êµ´ì´ ì˜†ìœ¼ë¡œ ëŒì•„ê°€ë©´ ë³¼ ì‚¬ì´ ê±°ë¦¬ê°€ ì¤„ì–´ë“¤ê±°ë‚˜, í•œìª½ ë³¼ì´ ì½”ì— ê°€ê¹Œì›Œì§
            # ì •ë©´ì„ ë³¼ ë•ŒëŠ” ë‘ ë³¼ì´ ì½”ì—ì„œ ë¹„ìŠ·í•œ ê±°ë¦¬ì— ìˆì–´ì•¼ í•¨
            # ë‹¨, ê±°ë¦¬ê°€ ë„ˆë¬´ ì‘ìœ¼ë©´ ê³„ì‚° ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•´ ìŠ¤í‚µ
            if max(left_distance, right_distance) > 0.01:
                distance_ratio = abs(left_distance - right_distance) / max(left_distance, right_distance)
                
                # ë°©ë²• 1ê³¼ ë°©ë²• 2ë¥¼ ëª¨ë‘ í†µê³¼í•´ì•¼ ì‹¤íŒ¨ (AND ì¡°ê±´)
                # ì¦‰, z-depth ì°¨ì´ë„ í¬ê³  ê±°ë¦¬ ë¹„ìœ¨ë„ í¬ë©´ ì‹¤íŒ¨
                # ë¯¼ê°ë„ ë‚®ì¶¤: ë” í° ì°¨ì´ê°€ ìˆì–´ì•¼ ì‹¤íŒ¨
                if distance_ratio > self.CHEEK_POSITION_THRESHOLD and z_diff > self.CHEEK_Z_DEPTH_THRESHOLD * 0.7:
                    # ë‘ ì¡°ê±´ì„ ëª¨ë‘ ë§Œì¡±í•˜ë©´ ì–¼êµ´ì´ ì˜†ìœ¼ë¡œ ëŒì•„ê°„ ê²ƒìœ¼ë¡œ íŒë‹¨
                    return False
            
            # ë°©ë²• 3: ë³¼ì˜ z ê°’ì´ ì½”ë³´ë‹¤ í¬ê²Œ ì°¨ì´ë‚˜ë©´ (ì–¼êµ´ì´ ì˜†ìœ¼ë¡œ ëŒì•„ê°)
            # ì´ ë°©ë²•ì€ z-depthê°€ ìœ íš¨í•  ë•Œë§Œ ì‚¬ìš©
            if abs(nose_z) > 0.001:  # nose_zê°€ ìœ íš¨í•œ ê²½ìš°ë§Œ
                left_z_diff = abs(left_cheek_z - nose_z)
                right_z_diff = abs(right_cheek_z - nose_z)
                
                # í•œìª½ ë³¼ì˜ z ê°’ì´ ì½”ì™€ í¬ê²Œ ì°¨ì´ë‚˜ê³ , ë™ì‹œì— z-depth ì°¨ì´ë„ í¬ë©´ ì‹¤íŒ¨
                # ë¯¼ê°ë„ ë‚®ì¶¤: ë” í° ì°¨ì´ê°€ ìˆì–´ì•¼ ì‹¤íŒ¨
                if (left_z_diff > self.CHEEK_NOSE_Z_THRESHOLD or right_z_diff > self.CHEEK_NOSE_Z_THRESHOLD) and z_diff > self.CHEEK_Z_DEPTH_THRESHOLD * 0.7:
                    return False
            
            # ëª¨ë“  ê²€ì¦ì„ í†µê³¼í•˜ë©´ ì–‘ìª½ ë³¼ì´ ë³´ì´ëŠ” ê²ƒìœ¼ë¡œ íŒë‹¨
            return True
            
        except (IndexError, AttributeError, ZeroDivisionError) as e:
            return False
    
    def calculate_face_orientation(self, landmarks, frame_width, frame_height):
        """ì–¼êµ´ ë°©í–¥ ê³„ì‚° (pitch, yaw) - ê¸°í•˜í•™ì  ê³„ì‚° ê¸°ë°˜"""
        # ì£¼ìš” ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ
        nose_tip = landmarks[self.NOSE_TIP]
        chin = landmarks[self.CHIN]
        left_eye_inner = landmarks[self.LEFT_EYE_INNER]
        left_eye_outer = landmarks[self.LEFT_EYE_OUTER]
        right_eye_inner = landmarks[self.RIGHT_EYE_INNER]
        right_eye_outer = landmarks[self.RIGHT_EYE_OUTER]
        forehead = landmarks[self.FOREHEAD]
        
        # 2D ì¢Œí‘œ ì¶”ì¶œ (x, yë§Œ ì‚¬ìš© - ë” ì•ˆì •ì )
        def get_2d(landmark):
            return np.array([landmark.x, landmark.y])
        
        nose_2d = get_2d(nose_tip)
        chin_2d = get_2d(chin)
        left_eye_inner_2d = get_2d(left_eye_inner)
        left_eye_outer_2d = get_2d(left_eye_outer)
        right_eye_inner_2d = get_2d(right_eye_inner)
        right_eye_outer_2d = get_2d(right_eye_outer)
        forehead_2d = get_2d(forehead)
        
        # ë‘ ëˆˆì˜ ì¤‘ì‹¬ì  ê³„ì‚°
        left_eye_center_2d = (left_eye_inner_2d + left_eye_outer_2d) / 2
        right_eye_center_2d = (right_eye_inner_2d + right_eye_outer_2d) / 2
        eye_center_2d = (left_eye_center_2d + right_eye_center_2d) / 2
        
        # ë‘ ëˆˆ ì‚¬ì´ì˜ ê±°ë¦¬ (ì •ê·œí™”ëœ ì¢Œí‘œ ê¸°ì¤€)
        eye_distance = np.linalg.norm(right_eye_center_2d - left_eye_center_2d)
        
        # ì–¼êµ´ ë†’ì´ (ì´ë§ˆì—ì„œ í„±ê¹Œì§€)
        face_height = np.linalg.norm(chin_2d - forehead_2d)
        
        # Yaw ê³„ì‚° (ì¢Œìš° íšŒì „) - ì½”ê°€ ë‘ ëˆˆ ì¤‘ì‹¬ì„ ì—ì„œ ì–¼ë§ˆë‚˜ ë²—ì–´ë‚¬ëŠ”ì§€
        # ì •ë©´ì„ ë³´ë©´ ì½”ëŠ” ë‘ ëˆˆ ì¤‘ì‹¬ì„ ì˜ ì¤‘ì•™ì— ìˆì–´ì•¼ í•¨
        eye_midpoint_x = eye_center_2d[0]
        nose_x = nose_2d[0]
        
        # ì½”ê°€ ëˆˆ ì¤‘ì‹¬ì„ ì—ì„œ ë²—ì–´ë‚œ ê±°ë¦¬ (ì •ê·œí™”)
        if eye_distance > 0:
            yaw_offset = (nose_x - eye_midpoint_x) / eye_distance
            # ê°ë„ë¡œ ë³€í™˜ (ëŒ€ëµì ì¸ ë³€í™˜: ì •ë©´ ê¸°ì¤€ Â±30ë„ ë²”ìœ„)
            # yaw_offsetì´ 0ì´ë©´ ì •ë©´, Â±0.5ë©´ ì•½ 30ë„ íšŒì „
            yaw_degrees = yaw_offset * 60.0  # ìŠ¤ì¼€ì¼ ì¡°ì •
        else:
            yaw_degrees = 0.0
        
        # Pitch ê³„ì‚° (ìƒí•˜ íšŒì „) - ì½”ê°€ ëˆˆ ì¤‘ì‹¬ì„ ì—ì„œ ì–¼ë§ˆë‚˜ ìœ„ì•„ë˜ë¡œ ë²—ì–´ë‚¬ëŠ”ì§€
        # ì •ë©´ì„ ë³´ë©´ ì½”ëŠ” ëˆˆ ì¤‘ì‹¬ì„ ë³´ë‹¤ ì•½ê°„ ì•„ë˜ì— ìˆì–´ì•¼ í•¨
        eye_midpoint_y = eye_center_2d[1]
        nose_y = nose_2d[1]
        
        # ì½”ê°€ ëˆˆ ì¤‘ì‹¬ì„ ë³´ë‹¤ ì•„ë˜ì— ìˆìœ¼ë©´ ì–‘ìˆ˜ (ì•„ë˜ë¡œ ê³ ê°œë¥¼ ìˆ™ì„)
        # ì½”ê°€ ëˆˆ ì¤‘ì‹¬ì„ ë³´ë‹¤ ìœ„ì— ìˆìœ¼ë©´ ìŒìˆ˜ (ìœ„ë¡œ ê³ ê°œë¥¼ ë“¦)
        if face_height > 0:
            # ì •ë©´ ê¸°ì¤€ìœ¼ë¡œ ì½”ëŠ” ëˆˆë³´ë‹¤ ì•½ê°„ ì•„ë˜ì— ìˆì–´ì•¼ í•¨
            # ì •ìƒì ì¸ ìœ„ì¹˜ ì°¨ì´ë¥¼ ë³´ì •
            normal_nose_offset = 0.05  # ì •ë©´ ê¸°ì¤€ ì½”ì˜ ì •ìƒ ìœ„ì¹˜ (ëˆˆë³´ë‹¤ ì•½ê°„ ì•„ë˜)
            pitch_offset = (nose_y - eye_midpoint_y - normal_nose_offset) / face_height
            # ê°ë„ë¡œ ë³€í™˜
            pitch_degrees = pitch_offset * 60.0  # ìŠ¤ì¼€ì¼ ì¡°ì •
        else:
            pitch_degrees = 0.0
        
        return pitch_degrees, yaw_degrees
    
    def draw_debug_info(self, frame, face_landmarks, avg_ear, pitch, yaw, is_sleeping, is_absent, is_gaze_away):
        """ë””ë²„ê·¸ ì •ë³´ë¥¼ í”„ë ˆì„ì— ê·¸ë¦¬ê¸°"""
        frame_height, frame_width = frame.shape[:2]
        
        # ìƒíƒœ ì •ë³´ í…ìŠ¤íŠ¸
        y_offset = 30
        font = cv2.FONT_HERSHEY_SIMPLEX
        font_scale = 0.6
        thickness = 2
        
        # ì–¼êµ´ ê°ì§€ ì—¬ë¶€ í‘œì‹œ
        if face_landmarks:
            # ì–¼êµ´ì´ ê°ì§€ë¨
            cv2.putText(frame, "Face: DETECTED", (10, y_offset),
                       font, font_scale, (0, 255, 0), thickness)
            
            # ëˆˆ ì˜ì—­ ê·¸ë¦¬ê¸°
            for eye_indices in [self.LEFT_EYE_EAR, self.RIGHT_EYE_EAR]:
                eye_points = []
                for idx in eye_indices:
                    if idx < len(face_landmarks):
                        point = face_landmarks[idx]
                        x = int(point.x * frame_width)
                        y = int(point.y * frame_height)
                        eye_points.append((x, y))
                        cv2.circle(frame, (x, y), 2, (0, 255, 0), -1)
                
                # ëˆˆ ìœ¤ê³½ì„  ê·¸ë¦¬ê¸°
                if len(eye_points) >= 4:
                    pts = np.array(eye_points, np.int32)
                    cv2.polylines(frame, [pts], True, (0, 255, 0), 1)
            
            # ë³¼ ê·¸ë¦¬ê¸° (GAZE_AWAY ê°ì§€ìš©)
            cheeks_visible = self.has_cheeks_visible(face_landmarks)
            
            # ì™¼ìª½ ë³¼
            if self.LEFT_CHEEK < len(face_landmarks):
                left_cheek = face_landmarks[self.LEFT_CHEEK]
                x = int(left_cheek.x * frame_width)
                y = int(left_cheek.y * frame_height)
                cheek_color = (0, 255, 0) if cheeks_visible else (0, 165, 255)
                cv2.circle(frame, (x, y), 6, cheek_color, -1)
                cv2.putText(frame, "L", (x + 8, y), font, 0.5, cheek_color, 2)
            
            # ì˜¤ë¥¸ìª½ ë³¼
            if self.RIGHT_CHEEK < len(face_landmarks):
                right_cheek = face_landmarks[self.RIGHT_CHEEK]
                x = int(right_cheek.x * frame_width)
                y = int(right_cheek.y * frame_height)
                cheek_color = (0, 255, 0) if cheeks_visible else (0, 165, 255)
                cv2.circle(frame, (x, y), 6, cheek_color, -1)
                cv2.putText(frame, "R", (x + 8, y), font, 0.5, cheek_color, 2)
            
            y_offset += 25
            
            # ë³¼ ê°€ì‹œì„± í‘œì‹œ
            cheek_status = "VISIBLE" if cheeks_visible else "NOT VISIBLE"
            cheek_color = (0, 255, 0) if cheeks_visible else (0, 165, 255)
            cv2.putText(frame, f"Cheeks: {cheek_status}", (10, y_offset),
                       font, font_scale, cheek_color, thickness)
            y_offset += 25
            
            # ë³¼ z-depth ì •ë³´ í‘œì‹œ (ë””ë²„ê·¸ìš©)
            if self.LEFT_CHEEK < len(face_landmarks) and self.RIGHT_CHEEK < len(face_landmarks) and self.NOSE_TIP < len(face_landmarks):
                left_cheek = face_landmarks[self.LEFT_CHEEK]
                right_cheek = face_landmarks[self.RIGHT_CHEEK]
                nose_tip = face_landmarks[self.NOSE_TIP]
                left_z = getattr(left_cheek, 'z', 0.0)
                right_z = getattr(right_cheek, 'z', 0.0)
                nose_z = getattr(nose_tip, 'z', 0.0)
                z_diff = abs(left_z - right_z)
                left_z_diff = abs(left_z - nose_z)
                right_z_diff = abs(right_z - nose_z)
                
                # ì½”ì—ì„œ ê° ë³¼ê¹Œì§€ì˜ ê±°ë¦¬
                nose_x, nose_y = nose_tip.x, nose_tip.y
                left_cheek_x, left_cheek_y = left_cheek.x, left_cheek.y
                right_cheek_x, right_cheek_y = right_cheek.x, right_cheek.y
                left_distance = np.sqrt((left_cheek_x - nose_x)**2 + (left_cheek_y - nose_y)**2)
                right_distance = np.sqrt((right_cheek_x - nose_x)**2 + (right_cheek_y - nose_y)**2)
                distance_ratio = abs(left_distance - right_distance) / max(left_distance, right_distance, 0.01) if max(left_distance, right_distance) > 0.01 else 0.0
                
                cv2.putText(frame, f"Z-diff: {z_diff:.3f} (th: {self.CHEEK_Z_DEPTH_THRESHOLD})", 
                           (10, y_offset), font, font_scale * 0.7, (255, 255, 255), 1)
                y_offset += 18
                cv2.putText(frame, f"L-z: {left_z_diff:.3f}, R-z: {right_z_diff:.3f} (th: {self.CHEEK_NOSE_Z_THRESHOLD})", 
                           (10, y_offset), font, font_scale * 0.7, (255, 255, 255), 1)
                y_offset += 18
                cv2.putText(frame, f"Dist-ratio: {distance_ratio:.3f} (th: {self.CHEEK_POSITION_THRESHOLD})", 
                           (10, y_offset), font, font_scale * 0.7, (255, 255, 255), 1)
                y_offset += 18
            
            # EAR ê°’
            ear_color = (0, 255, 0) if avg_ear >= self.EAR_THRESHOLD else (0, 0, 255)
            cv2.putText(frame, f"EAR: {avg_ear:.3f}", (10, y_offset), 
                       font, font_scale, ear_color, thickness)
            y_offset += 25
            
            # ì–¼êµ´ ë°©í–¥ (ì‹œì„  ë²—ì–´ë‚¨ ì—¬ë¶€ì— ë”°ë¼ ìƒ‰ìƒ ë³€ê²½)
            gaze_color = (0, 255, 0) if not is_gaze_away else (0, 165, 255)  # ì •ìƒ: ì´ˆë¡, ë²—ì–´ë‚¨: ì£¼í™©
            cv2.putText(frame, f"Pitch: {pitch:.1f}deg, Yaw: {yaw:.1f}deg", (10, y_offset),
                       font, font_scale, gaze_color, thickness)
            y_offset += 25
            
            # ì‹œì„  ë²—ì–´ë‚¨ í”„ë ˆì„ ìˆ˜
            gaze_away_color = (255, 255, 255) if not is_gaze_away else (0, 165, 255)
            cv2.putText(frame, f"Gaze Away Frames: {self.gaze_away_counter}/{self.GAZE_AWAY_CONSECUTIVE_FRAMES}", 
                       (10, y_offset), font, font_scale, gaze_away_color, thickness)
            y_offset += 25
            
            # ëˆˆ ê°ìŒ í”„ë ˆì„ ìˆ˜
            cv2.putText(frame, f"Closed Frames: {self.eye_closed_counter}/{self.EAR_CONSECUTIVE_FRAMES}", 
                       (10, y_offset), font, font_scale, (255, 255, 255), thickness)
            y_offset += 25
        else:
            # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ
            cv2.putText(frame, "Face: NOT DETECTED", (10, y_offset),
                       font, font_scale, (0, 0, 255), thickness)
            y_offset += 25
            
            # ì–¼êµ´ ë¶€ì¬ í”„ë ˆì„ ìˆ˜
            cv2.putText(frame, f"No Face Frames: {self.no_face_counter}/{self.NO_FACE_CONSECUTIVE_FRAMES}", 
                       (10, y_offset), font, font_scale, (255, 255, 255), thickness)
            y_offset += 25
        
        # ìƒíƒœ í‘œì‹œ (í•­ìƒ í‘œì‹œ)
        if is_sleeping:
            cv2.putText(frame, "SLEEPING!", (10, y_offset),
                       font, 0.8, (0, 0, 255), 2)
            y_offset += 30
        if is_absent:
            cv2.putText(frame, "ABSENT!", (10, y_offset),
                       font, 0.8, (255, 0, 0), 2)
            y_offset += 30
        if is_gaze_away:
            cv2.putText(frame, "GAZE AWAY!", (10, y_offset),
                       font, 0.8, (0, 165, 255), 2)
            y_offset += 30
        
        return frame

    def stop(self):
        """ì‘ì—… ì¢…ë£Œ"""
        self.running = False
        self.wait()

    def run(self):
        self.running = True
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("[ERROR] ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ìº ì´ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            self.running = False
            return
        
        print("[OK] ì›¹ìº  ì—°ê²° ì„±ê³µ - Vision Worker ì‹œì‘")
        
        try:
            while self.running:
                try:
                    ret, frame = cap.read()
                    if not ret:
                        print("[WARNING] í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        continue
                    
                    # MediaPipe Face Landmarker ì²˜ë¦¬
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    mp_image = MPImage(image_format=ImageFormat.SRGB, data=frame_rgb)
                    detection_result = self.face_landmarker.detect(mp_image)
                    
                    is_sleeping = False
                    is_absent = False
                    is_gaze_away = False
                    avg_ear = 0.0  # ê¸°ë³¸ê°’
                    pitch, yaw = 0.0, 0.0  # ì–¼êµ´ ë°©í–¥ (ê°ë„, ë„ ë‹¨ìœ„)
                    
                    if detection_result.face_landmarks:
                        # ì–¼êµ´ì´ ê°ì§€ë¨ - ì–¼êµ´ ë¶€ì¬ ì¹´ìš´í„° ë¦¬ì…‹
                        self.no_face_counter = 0
                        face_landmarks = detection_result.face_landmarks[0]  # ì²« ë²ˆì§¸ ì–¼êµ´
                        
                        # ëˆˆ ê°ìŒ ê°ì§€ (EAR ê³„ì‚°)
                        left_ear = self.calculate_ear(face_landmarks, self.LEFT_EYE_EAR)
                        right_ear = self.calculate_ear(face_landmarks, self.RIGHT_EYE_EAR)
                        avg_ear = (left_ear + right_ear) / 2.0
                        
                        # ëˆˆì´ ê°ê²¼ëŠ”ì§€ í™•ì¸
                        if avg_ear < self.EAR_THRESHOLD:
                            # ëˆˆì´ ê°ìŒ - ì¹´ìš´í„° ì¦ê°€
                            self.eye_closed_counter += 1
                        else:
                            # ëˆˆì´ ì—´ë¦¼ - ì¹´ìš´í„° ë¦¬ì…‹
                            self.eye_closed_counter = 0
                        
                        # ì—°ì†ìœ¼ë¡œ ëˆˆì„ ê°ê³  ìˆìœ¼ë©´ ì¡¸ìŒ ê°ì§€
                        if self.eye_closed_counter >= self.EAR_CONSECUTIVE_FRAMES:
                            is_sleeping = True
                        
                        # ì–¼êµ´ ë°©í–¥ ê³„ì‚° (ë””ë²„ê·¸ìš©) - ê°ë„(ë„) ë‹¨ìœ„ë¡œ ë°˜í™˜
                        pitch_degrees, yaw_degrees = self.calculate_face_orientation(
                            face_landmarks, frame.shape[1], frame.shape[0]
                        )
                        pitch, yaw = pitch_degrees, yaw_degrees
                        
                        # ì‹œì„  ë²—ì–´ë‚¨ ê°ì§€ (ë³¼ ê°€ì‹œì„± ê¸°ì¤€)
                        cheeks_visible = self.has_cheeks_visible(face_landmarks)
                        
                        if not cheeks_visible:
                            # ë³¼ ì¤‘ í•˜ë‚˜ë¼ë„ ì•ˆ ë³´ì´ë©´ ì‹œì„ ì´ ë²—ì–´ë‚œ ê²ƒìœ¼ë¡œ íŒë‹¨
                            self.gaze_away_counter += 1
                        else:
                            # ì–‘ìª½ ë³¼ì´ ëª¨ë‘ ë³´ì´ë©´ ì •ìƒ ë²”ìœ„ - ì¹´ìš´í„° ë¦¬ì…‹
                            self.gaze_away_counter = 0
                        
                        # ì—°ì†ìœ¼ë¡œ ë³¼ì´ ì•ˆ ë³´ì´ë©´ GAZE_AWAY ê°ì§€
                        if self.gaze_away_counter >= self.GAZE_AWAY_CONSECUTIVE_FRAMES:
                            is_gaze_away = True
                    else:
                        # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ - ì–¼êµ´ ë¶€ì¬ ì¹´ìš´í„° ì¦ê°€
                        self.no_face_counter += 1
                        # ì–¼êµ´ì´ ì—†ìœ¼ë©´ ëˆˆ ê°ìŒ ì¹´ìš´í„°ì™€ ì‹œì„  ë²—ì–´ë‚¨ ì¹´ìš´í„°ë„ ë¦¬ì…‹
                        self.eye_closed_counter = 0
                        self.gaze_away_counter = 0
                        
                        # ì–¼êµ´ì´ ì¼ì • ì‹œê°„ ë™ì•ˆ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ë¶€ì¬ ê°ì§€
                        if self.no_face_counter >= self.NO_FACE_CONSECUTIVE_FRAMES:
                            is_absent = True
                    
                    # ì¡¸ìŒ ê°ì§€ ì‹œ Packet ë°œì†¡
                    if is_sleeping:
                        if self.should_alert(VisionEvents.SLEEPING):
                            packet = Packet(
                                event=VisionEvents.SLEEPING,
                                data={"confidence": 0.9, "ear": avg_ear},
                                meta=PacketMeta(category=PacketCategory.VISION)
                            )
                            self.alert_signal.emit(packet)
                    
                    # ì–¼êµ´ ë¶€ì¬ ê°ì§€ ì‹œ Packet ë°œì†¡
                    if is_absent:
                        if self.should_alert(VisionEvents.ABSENT):
                            packet = Packet(
                                event=VisionEvents.ABSENT,
                                data={"confidence": 0.9, "duration": self.no_face_counter},
                                meta=PacketMeta(category=PacketCategory.VISION)
                            )
                            self.alert_signal.emit(packet)
                    
                    # ì‹œì„  ë²—ì–´ë‚¨ ê°ì§€ ì‹œ Packet ë°œì†¡ (ë³¼ì´ ì•ˆ ë³´ì„)
                    if is_gaze_away:
                        if self.should_alert(VisionEvents.GAZE_AWAY):
                            packet = Packet(
                                event=VisionEvents.GAZE_AWAY,
                                data={
                                    "confidence": 0.9, 
                                    "reason": "cheek_not_visible",
                                    "duration": self.gaze_away_counter
                                },
                                meta=PacketMeta(category=PacketCategory.VISION)
                            )
                            self.alert_signal.emit(packet)
                    
                    # ë””ë²„ê·¸ ì´ë¯¸ì§€ ì†¡ì¶œ (GUIì—ì„œ í‘œì‹œí•˜ê¸° ìœ„í•¨)
                    if self.show_debug_window:
                        # ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ
                        face_landmarks_for_draw = None
                        if detection_result.face_landmarks:
                            face_landmarks_for_draw = detection_result.face_landmarks[0]
                        
                        debug_frame = self.draw_debug_info(
                            frame.copy(), 
                            face_landmarks_for_draw,
                            avg_ear, pitch, yaw, is_sleeping, is_absent, is_gaze_away
                        )
                        # OpenCV ì°½ ëŒ€ì‹  ì‹œê·¸ë„ ì „ì†¡
                        self.debug_frame_signal.emit(debug_frame)
                    
                    # time.sleep(0.05) # 0.1ì´ˆ ëŒ€ê¸° (10 FPS)
                
                except Exception as e:
                    # í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ ì¶œë ¥í•˜ê³  ê³„ì† ì§„í–‰
                    print(f"[ERROR] í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    import traceback
                    traceback.print_exc()
                    # ì˜ˆì™¸ ë°œìƒí•´ë„ ë£¨í”„ëŠ” ê³„ì† ì§„í–‰ (ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬)
                    continue
        
        except Exception as e:
            # ì „ì²´ ë£¨í”„ì—ì„œ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ ì‹œ
            print(f"[ERROR] Vision Worker ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # ì •ë¦¬ ì‘ì—…ì€ í•­ìƒ ì‹¤í–‰
            self.running = False
            cap.release()
            
            # ì—¬ê¸°ì„œ OpenCV ì°½ ë‹«ëŠ” ì½”ë“œëŠ” ì‚­ì œ (UIì—ì„œ ê´€ë¦¬)
            print("[OK] Vision Worker ì¢…ë£Œ")
    
    def stop(self):
        """ìŠ¤ë ˆë“œ ì¢…ë£Œ"""
        self.running = False