# client/services/vision.py
import sys
import os
from PyQt6.QtCore import QThread, pyqtSignal
import cv2
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
from mediapipe import Image as MPImage
from mediapipe.tasks.python.vision.core.image import ImageFormat
import numpy as np
import time
from collections import deque

# shared í´ë” importë¥¼ ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from shared.protocol import Packet, PacketMeta
from shared.constants import VisionEvents, PacketCategory

class VisionWorker(QThread):
    # ë©”ì¸ UIë¡œ ë³´ë‚¼ ì‹ í˜¸ ì •ì˜
    alert_signal = pyqtSignal(object) # Packet ê°ì²´ë¥¼ ë³´ëƒ„

    def __init__(self):
        super().__init__()
        self.running = False
        # MediaPipe Face Landmarker ì´ˆê¸°í™” (0.10.x API)
        # ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        model_path = os.path.join(os.path.dirname(__file__), 'face_landmarker.task')
        
        if not os.path.exists(model_path):
            raise FileNotFoundError(
                f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}\n"
                f"ë‹¤ìŒ ëª…ë ¹ìœ¼ë¡œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”: python download_mediapipe_model.py"
            )
        
        base_options = python.BaseOptions(model_asset_path=model_path)
        
        options = vision.FaceLandmarkerOptions(
            base_options=base_options,
            output_face_blendshapes=False,
            output_facial_transformation_matrixes=False,
            num_faces=1,
            min_face_detection_confidence=0.5,
            min_face_presence_confidence=0.5,
            min_tracking_confidence=0.5,
            running_mode=vision.RunningMode.IMAGE  # ì´ë¯¸ì§€ ëª¨ë“œ
        )
        
        try:
            self.face_landmarker = vision.FaceLandmarker.create_from_options(options)
        except Exception as e:
            print(f"âš ï¸ FaceLandmarker ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ëª¨ë¸ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•˜ê±°ë‚˜ ë‹¤ë¥¸ ë°©ë²•ì„ ì‹œë„í•´ì£¼ì„¸ìš”.")
            raise
        
        # ìƒíƒœ ì¶”ì 
        self.eye_closed_frames = deque(maxlen=20)  # ìµœê·¼ 20í”„ë ˆì„ ì¶”ì  (ì•½ 2ì´ˆ)
        self.no_face_frames = deque(maxlen=30)  # ìµœê·¼ 30í”„ë ˆì„ ì¶”ì  (ì•½ 3ì´ˆ)
        self.last_alert_time = {}  # ê° ì´ë²¤íŠ¸ë³„ ë§ˆì§€ë§‰ ì•Œë¦¼ ì‹œê°„ (ì¤‘ë³µ ë°©ì§€)
        
        # EAR ì„ê³„ê°’
        self.EAR_THRESHOLD = 0.25  # ëˆˆ ê°ìŒ ì„ê³„ê°’
        self.EAR_CONSECUTIVE_FRAMES = 20  # ì—°ì† í”„ë ˆì„ ìˆ˜ (ì•½ 2ì´ˆ)
        
        # ëˆˆ ëœë“œë§ˆí¬ ì¸ë±ìŠ¤ (EAR ê³„ì‚°ìš©)
        self.LEFT_EYE_EAR = [33, 160, 158, 133, 153, 144]
        self.RIGHT_EYE_EAR = [362, 385, 387, 263, 390, 374]
    
    def calculate_ear(self, landmarks, eye_indices):
        """Eye Aspect Ratio (EAR) ê³„ì‚°"""
        # MediaPipe 0.10.xëŠ” landmarksê°€ ë¦¬ìŠ¤íŠ¸ í˜•íƒœ
        # ìˆ˜ì§ ê±°ë¦¬ ê³„ì‚°
        vertical_1 = np.linalg.norm(
            np.array([landmarks[eye_indices[1]].x, landmarks[eye_indices[1]].y]) -
            np.array([landmarks[eye_indices[5]].x, landmarks[eye_indices[5]].y])
        )
        vertical_2 = np.linalg.norm(
            np.array([landmarks[eye_indices[2]].x, landmarks[eye_indices[2]].y]) -
            np.array([landmarks[eye_indices[4]].x, landmarks[eye_indices[4]].y])
        )
        
        # ìˆ˜í‰ ê±°ë¦¬ ê³„ì‚°
        horizontal = np.linalg.norm(
            np.array([landmarks[eye_indices[0]].x, landmarks[eye_indices[0]].y]) -
            np.array([landmarks[eye_indices[3]].x, landmarks[eye_indices[3]].y])
        )
        
        # EAR ê³„ì‚°
        if horizontal == 0:
            return 0.0
        ear = (vertical_1 + vertical_2) / (2.0 * horizontal)
        return ear
    
    def should_alert(self, event_type, cooldown_seconds=5):
        """ì¤‘ë³µ ì•Œë¦¼ ë°©ì§€ (ì¿¨ë‹¤ìš´)"""
        current_time = time.time()
        last_time = self.last_alert_time.get(event_type, 0)
        
        if current_time - last_time < cooldown_seconds:
            return False
        
        self.last_alert_time[event_type] = current_time
        return True

    def run(self):
        self.running = True
        cap = cv2.VideoCapture(0)
        if not cap.isOpened():
            print("[ERROR] ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì›¹ìº ì´ ì—°ê²°ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
            self.running = False
            return
        
        print("[OK] ì›¹ìº  ì—°ê²° ì„±ê³µ - Vision Worker ì‹œì‘")
        
        try:
            while self.running:
                try:
                    ret, frame = cap.read()
                    if not ret:
                        print("[WARNING] í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                        continue
                    
                    # MediaPipe Face Landmarker ì²˜ë¦¬
                    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                    mp_image = MPImage(image_format=ImageFormat.SRGB, data=frame_rgb)
                    detection_result = self.face_landmarker.detect(mp_image)
                    
                    is_sleeping = False
                    is_absent = False
                    avg_ear = 0.0  # ê¸°ë³¸ê°’
                    
                    if detection_result.face_landmarks:
                        # ì–¼êµ´ì´ ê°ì§€ë¨
                        self.no_face_frames.append(True)
                        face_landmarks = detection_result.face_landmarks[0]  # ì²« ë²ˆì§¸ ì–¼êµ´
                        
                        # ëˆˆ ê°ìŒ ê°ì§€ (EAR ê³„ì‚°)
                        left_ear = self.calculate_ear(face_landmarks, self.LEFT_EYE_EAR)
                        right_ear = self.calculate_ear(face_landmarks, self.RIGHT_EYE_EAR)
                        avg_ear = (left_ear + right_ear) / 2.0
                        
                        # ëˆˆì´ ê°ê²¼ëŠ”ì§€ í™•ì¸
                        if avg_ear < self.EAR_THRESHOLD:
                            self.eye_closed_frames.append(True)
                        else:
                            self.eye_closed_frames.append(False)
                        
                        # ì—°ì†ìœ¼ë¡œ ëˆˆì„ ê°ê³  ìˆìœ¼ë©´ ì¡¸ìŒ ê°ì§€
                        if len(self.eye_closed_frames) >= self.EAR_CONSECUTIVE_FRAMES:
                            if all(self.eye_closed_frames):
                                is_sleeping = True
                    else:
                        # ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•ŠìŒ
                        self.no_face_frames.append(False)
                        self.eye_closed_frames.append(False)
                        
                        # ì–¼êµ´ì´ ì¼ì • ì‹œê°„ ë™ì•ˆ ê°ì§€ë˜ì§€ ì•Šìœ¼ë©´ ë¶€ì¬ ê°ì§€
                        if len(self.no_face_frames) >= 30:  # ì•½ 3ì´ˆ
                            if not any(self.no_face_frames):
                                is_absent = True
                    
                    # ì¡¸ìŒ ê°ì§€ ì‹œ Packet ë°œì†¡
                    if is_sleeping:
                        if self.should_alert(VisionEvents.SLEEPING):
                            packet = Packet(
                                event=VisionEvents.SLEEPING,
                                data={"confidence": 0.9, "ear": avg_ear},
                                meta=PacketMeta(category=PacketCategory.VISION)
                            )
                            self.alert_signal.emit(packet)
                    
                    # ì–¼êµ´ ë¶€ì¬ ê°ì§€ ì‹œ Packet ë°œì†¡
                    if is_absent:
                        if self.should_alert(VisionEvents.ABSENT):
                            packet = Packet(
                                event=VisionEvents.ABSENT,
                                data={"confidence": 0.9, "duration": len(self.no_face_frames) * 0.1},
                                meta=PacketMeta(category=PacketCategory.VISION)
                            )
                            self.alert_signal.emit(packet)
                    
                    # time.sleep(0.05) # 0.1ì´ˆ ëŒ€ê¸° (10 FPS)
                
                except Exception as e:
                    # í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ ì‹œ ë¡œê·¸ ì¶œë ¥í•˜ê³  ê³„ì† ì§„í–‰
                    print(f"[ERROR] í”„ë ˆì„ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                    import traceback
                    traceback.print_exc()
                    # ì˜ˆì™¸ ë°œìƒí•´ë„ ë£¨í”„ëŠ” ê³„ì† ì§„í–‰ (ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬)
                    continue
        
        except Exception as e:
            # ì „ì²´ ë£¨í”„ì—ì„œ ì¹˜ëª…ì  ì˜¤ë¥˜ ë°œìƒ ì‹œ
            print(f"[ERROR] Vision Worker ì¹˜ëª…ì  ì˜¤ë¥˜: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # ì •ë¦¬ ì‘ì—…ì€ í•­ìƒ ì‹¤í–‰
            self.running = False
            cap.release()
            print("[OK] Vision Worker ì¢…ë£Œ")
    
    def stop(self):
        """ìŠ¤ë ˆë“œ ì¢…ë£Œ"""
        self.running = False