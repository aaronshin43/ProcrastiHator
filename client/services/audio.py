import threading
import queue
import sounddevice as sd
import numpy as np
import asyncio
from livekit import rtc

# Per-voice playback gain (live agent audio). Values >1.0 amplify but may clip.
VOICE_GAIN_MULTIPLIER = {
    # Boost to match Gordon Ramsey perceived loudness
    "Anime Girl": 3.0,
    "Shakespeare": 3.0,
}


def _apply_gain_int16(data: np.ndarray, gain: float) -> np.ndarray:
    """Apply gain to int16 PCM with clipping."""
    if gain <= 1.0:
        return data

    # Convert to int32 for headroom, apply gain, clip back to int16.
    amplified = (data.astype(np.int32) * gain).round()
    np.clip(amplified, -32768, 32767, out=amplified)
    return amplified.astype(np.int16)

class AudioSink(threading.Thread):
    def __init__(self):
        super().__init__()
        self.queue = queue.Queue()
        self.daemon = True
        self.stream = None
        self._stop_event = threading.Event()

    def run(self):
        while not self._stop_event.is_set():
            try:
                # íì—ì„œ ì˜¤ë””ì˜¤ í”„ë ˆìž„ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (íƒ€ìž„ì•„ì›ƒ ì„¤ì •ìœ¼ë¡œ ì¢…ë£Œ ì²´í¬)
                frame_info = self.queue.get(timeout=0.5)
            except queue.Empty:
                continue

            data, sample_rate, channels = frame_info

            # ìŠ¤íŠ¸ë¦¼ ì´ˆê¸°í™” ë˜ëŠ” í¬ë§· ë³€ê²½ ì‹œ ìž¬ì´ˆê¸°í™”
            if self.stream is None or self.stream.samplerate != sample_rate or self.stream.channels != channels:
                if self.stream:
                    self.stream.stop()
                    self.stream.close()
                
                try:
                    self.stream = sd.OutputStream(
                        samplerate=sample_rate,
                        channels=channels,
                        dtype='int16'
                    )
                    self.stream.start()
                    print(f"ðŸ”Š Audio Sink Initialized: {sample_rate}Hz, {channels}ch")
                except Exception as e:
                    print(f"âŒ Failed to initialize audio stream: {e}")
                    continue

            # ì˜¤ë””ì˜¤ ìž¬ìƒ (Blocking Write)
            try:
                self.stream.write(data)
            except Exception as e:
                print(f"âŒ Audio Write Error: {e}")

    def put_frame(self, frame: rtc.AudioFrame):
        # AudioFrameì„ numpyë¡œ ë³€í™˜ ë° ì •ë³´ ì¶”ì¶œ
        # frame.dataëŠ” int16 memoryview
        data = np.frombuffer(frame.data, dtype=np.int16)

        # Boost quiet voices (Anime Girl / Shakespeare) on playback.
        # We read the current selected voice from UI globals.
        try:
            from client.ui import name as ui_name

            voice_name = getattr(ui_name, "user_voice", "") or ""
            gain = float(VOICE_GAIN_MULTIPLIER.get(voice_name, 1.0))
            if gain != 1.0:
                data = _apply_gain_int16(data, gain)
        except Exception:
            pass

        # livekit 0.17+ AudioFrame uses num_channels instead of channels
        self.queue.put((data, frame.sample_rate, frame.num_channels))
    
    def clear(self):
        """íë¥¼ ë¹„ì›Œ ìž¬ìƒì„ ì¦‰ì‹œ ì¤‘ë‹¨í•˜ëŠ” íš¨ê³¼"""
        with self.queue.mutex:
            self.queue.queue.clear()
        
        # ìŠ¤íŠ¸ë¦¼ë„ í”ŒëŸ¬ì‹œ (ê°€ëŠ¥í•˜ë‹¤ë©´) - sounddeviceëŠ” abortê°€ ìžˆê¸´ í•¨
        if self.stream and self.stream.active:
             self.stream.abort()
             self.stream.close()
             self.stream = None

    def stop(self):
        self._stop_event.set()
        if self.stream:
            self.stream.stop()
            self.stream.close()

class AudioPlayer:
    def __init__(self, loop: asyncio.AbstractEventLoop):
        self.loop = loop
        self.sink = AudioSink()
        self.sink.start()
        self.task = None
        self._is_muted = False  # Track interruption state

    def set_muted(self, muted: bool):
        self._is_muted = muted
        if muted:
            self.sink.clear()

    async def start(self, track: rtc.Track):
        self.task = self.loop.create_task(self._consume_track(track))

    async def _consume_track(self, track: rtc.Track):
        audio_stream = rtc.AudioStream(track)
        print(f"ðŸŽ§ Started listening to track: {track.sid}")
        try:
            async for event in audio_stream:
                if self._is_muted:
                    continue  # Muted ìƒíƒœë©´ ìž¬ìƒ íì— ë„£ì§€ ì•Šê³  ë²„ë¦¼
                
                # LiveKit 0.17.x ì´ìƒì—ì„œëŠ” AudioStreamì´ AudioFrameEventë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
                # ì‹¤ì œ ì˜¤ë””ì˜¤ ë°ì´í„°ëŠ” event.frameì— ë“¤ì–´ìžˆìŠµë‹ˆë‹¤.
                self.sink.put_frame(event.frame)
        except Exception as e:
            print(f"âŒ Audio consumption logic error: {e}")
        finally:
            print(f"ðŸ”‡ Stopped listening to track: {track.sid}")

    def stop(self):
        if self.task:
            self.task.cancel()
        self.sink.stop()
        
    async def stop_async(self):
        """Helper for async context"""
        self.sink.clear()

    async def stop_async(self):
        """ì¸í„°ëŸ½íŠ¸ìš©: ì¦‰ì‹œ ìž¬ìƒì„ ë©ˆì¶”ê³  íë¥¼ ë¹„ì›€"""
        self.sink.clear()
        print("ðŸ”‡ Audio Player Interrupted (Cleared Buffer)")
